{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = 'https://canvas.illinois.edu' \n",
    "\n",
    "# File paths\n",
    "rubric_file = 'docs/rubric_data.json'\n",
    "discussion_entries_file = 'docs/discussion_entries.json'\n",
    "\n",
    "# Make sure the 'docs' directory exists\n",
    "os.makedirs('docs', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts individual discussion entries from the Canvas LMS API.\n",
    "# Individual discussion entries are the replies to the original discussion post.\n",
    "# It takes the base URL of the Canvas instance, course ID, discussion topic ID, and headers for authentication.\n",
    "# It returns a list of individual entries with their details such as ID, parent ID, user ID, and message content.\n",
    "\n",
    "def extract_individual_discussion(base_url, course_id, discussion_topic_id, headers):\n",
    "    individual_entries = []\n",
    "    discussion_url = f'{base_url}/api/v1/courses/{course_id}/discussion_topics/{discussion_topic_id}/view'\n",
    "\n",
    "    discussion_response = requests.get(discussion_url, headers=headers)\n",
    "    if discussion_response.ok:\n",
    "        discussion_data = discussion_response.json()\n",
    "        entries = extract_entries(discussion_data['view'], discussion_data['participants'])\n",
    "        individual_entries.extend(entries)\n",
    "    else:\n",
    "        print(f\"Error fetching individual discussion: {discussion_response.text}\")\n",
    "\n",
    "    return individual_entries\n",
    "\n",
    "\n",
    "course_id = '32545'\n",
    "discussion_topic_id = '352017'\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "individual_discussion_data = extract_individual_discussion(base_url, course_id, discussion_topic_id, headers)\n",
    "print(json.dumps(individual_discussion_data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This function extracts entries from the discussion data.\n",
    "# It takes a list of entries and participants as input.\n",
    "# It returns a list of entries with their details such as ID, parent ID, user ID, name, message content, and replies.\n",
    "def extract_entries(entries, participants):\n",
    "    result = []\n",
    "    for entry in entries:\n",
    "        if 'message' in entry and 'deleted' not in entry:\n",
    "            id = entry['id']\n",
    "            parent_id = entry.get('parent_id')\n",
    "            user_id = entry.get('user_id')\n",
    "            \n",
    "            # Find participant name, handle missing 'name' key\n",
    "            participant = next((p for p in participants if p.get('id') == user_id), None)\n",
    "            name = participant.get('name') if participant else \"Unknown\"\n",
    "\n",
    "            message = entry['message']\n",
    "            replies = extract_entries(entry.get('replies', []), participants)\n",
    "            result.append({'id': id, 'parent_id': parent_id, 'name': name, 'message': message, 'replies': replies})\n",
    "    return result\n",
    "\n",
    "# This function extracts group discussions from the Canvas LMS API.\n",
    "# Group discussions are the discussions that are created for seperate groups.\n",
    "# It takes the base URL of the Canvas instance, headers for authentication, and group topic children as input.\n",
    "# It returns a list of group entries with their details such as group ID and entries.\n",
    "def extract_group_discussions(base_url, headers, group_topic_children):\n",
    "    group_entries = []\n",
    "    for group_topic in group_topic_children:\n",
    "        group_id = group_topic['group_id']\n",
    "        topic_id = group_topic['id']\n",
    "        group_discussion_url = f'{base_url}/api/v1/groups/{group_id}/discussion_topics/{topic_id}/view'\n",
    "\n",
    "        group_discussion_response = requests.get(group_discussion_url, headers=headers)\n",
    "        if group_discussion_response.ok:\n",
    "            group_discussion_data = group_discussion_response.json()\n",
    "            entries = extract_entries(group_discussion_data['view'], group_discussion_data['participants'])\n",
    "            group_entries.append({'group_id': group_id, 'entries': entries})\n",
    "        else:\n",
    "            print(f\"Error fetching group discussion for group {group_id}: {group_discussion_response.text}\")\n",
    "\n",
    "    return group_entries\n",
    "\n",
    "# This function fetches the main discussion topic from the Canvas LMS API.\n",
    "# It takes the base URL of the Canvas instance, course ID, discussion topic ID, and headers for authentication as input.\n",
    "# It returns the main discussion topic data if the request is successful, otherwise it returns None.\n",
    "def fetch_main_discussion_topic(base_url, course_id, discussion_topic_id, headers):\n",
    "    url = f'{base_url}/api/v1/courses/{course_id}/discussion_topics/{discussion_topic_id}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.ok:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching main discussion topic: {response.text}\")\n",
    "        return None\n",
    "\n",
    "course_id = '32545'\n",
    "discussion_topic_id = '352017'\n",
    "main_discussion_topic = fetch_main_discussion_topic(base_url, course_id, discussion_topic_id, headers)\n",
    "if main_discussion_topic and 'group_topic_children' in main_discussion_topic:\n",
    "    group_discussions = extract_group_discussions(base_url, headers, main_discussion_topic['group_topic_children'])\n",
    "print(json.dumps(group_discussions, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No instruction data found\n"
     ]
    }
   ],
   "source": [
    "# Extracts the instructions and rubric from the Canvas LMS API.\n",
    "# Gets data from the assignment field from the discussion data.\n",
    "def extract_and_save_instruction_base(base_url, course_id, discussion_topic_id, headers, rubric_file):\n",
    "    instruction_url = f'{base_url}/api/v1/courses/{course_id}/discussion_topics/{discussion_topic_id}'\n",
    "    instruction_response = requests.get(instruction_url, headers=headers)\n",
    "\n",
    "    if instruction_response.ok:\n",
    "        instruction_data = instruction_response.json()\n",
    "        rubric = []\n",
    "\n",
    "        # Extract title\n",
    "        title = instruction_data.get('title')\n",
    "        if title:\n",
    "            rubric.append({'title': title})\n",
    "\n",
    "        # Extract instruction description\n",
    "        if 'description' in instruction_data.get('assignment', {}):\n",
    "            message_html = instruction_data['assignment']['description']\n",
    "            soup = BeautifulSoup(message_html, 'html.parser')\n",
    "            message = soup.get_text()\n",
    "            rubric.append({'instruction': message})\n",
    "\n",
    "        # Extract rubric and points possible\n",
    "        if 'rubric' in instruction_data.get('assignment', {}) and 'description' in instruction_data['assignment']:\n",
    "            rubric.extend(instruction_data['assignment']['rubric'])\n",
    "\n",
    "            points_possible = instruction_data['assignment'].get('points_possible')\n",
    "            if points_possible is not None:\n",
    "                rubric.append({'points_possible': points_possible})\n",
    "\n",
    "            # Handling the 'docs' folder\n",
    "            if not os.path.exists('docs'):\n",
    "                os.makedirs('docs')\n",
    "\n",
    "            # Save to JSON file\n",
    "            with open(rubric_file, 'w') as f:\n",
    "                json.dump(rubric, f)\n",
    "\n",
    "            print(\"Extracted instructions and rubric\")\n",
    "        else:\n",
    "            print(\"No instruction data found\")\n",
    "    else:\n",
    "        print(f'Error: {instruction_response.text}')\n",
    "\n",
    "course_id = '32545'\n",
    "discussion_topic_id = '352012'\n",
    "extract_and_save_instruction_base(base_url, course_id, discussion_topic_id, headers, rubric_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fetches and displays the raw discussion data from the Canvas LMS API.\n",
    "# It takes the base URL of the Canvas instance, course ID, discussion topic ID, and headers for authentication as input.\n",
    "# The function prints the raw JSON data of the discussion topic if the request is successful.\n",
    "# If the request fails, it prints an error message with the response text.\n",
    "def fetch_and_display_raw_discussion_data(base_url, course_id, discussion_topic_id, headers):\n",
    "    instruction_url = f'{base_url}/api/v1/courses/{course_id}/discussion_topics/{discussion_topic_id}'\n",
    "    response = requests.get(instruction_url, headers=headers)\n",
    "\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        print(json.dumps(data, indent=4))  # Pretty print the JSON data\n",
    "    else:\n",
    "        print(f'Error fetching data: {response.status_code}, {response.text}')\n",
    "\n",
    "#course_id = '42126'\n",
    "#discussion_topic_id = '531789'        \n",
    "fetch_and_display_raw_discussion_data(base_url, course_id, discussion_topic_id, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted instructions and rubric\n"
     ]
    }
   ],
   "source": [
    "# Solves the problem of not fetching isntructions if not in structured format\n",
    "# This function extracts the instructions and rubric from the Message field.\n",
    "def extract_and_save_instruction_message(base_url, course_id, discussion_topic_id, headers, rubric_file):\n",
    "    instruction_url = f'{base_url}/api/v1/courses/{course_id}/discussion_topics/{discussion_topic_id}'\n",
    "    instruction_response = requests.get(instruction_url, headers=headers)\n",
    "\n",
    "    if instruction_response.ok:\n",
    "        instruction_data = instruction_response.json()\n",
    "        rubric = []\n",
    "\n",
    "        # Extract title\n",
    "        title = instruction_data.get('title')\n",
    "        if title:\n",
    "            rubric.append({'title': title})\n",
    "\n",
    "        # Extract message\n",
    "        message_html = instruction_data.get('message')\n",
    "        if message_html:\n",
    "            soup = BeautifulSoup(message_html, 'html.parser')\n",
    "\n",
    "            # Replace <br> tags with newlines\n",
    "            for br in soup.find_all(\"br\"):\n",
    "                br.replace_with(\"\\n\")\n",
    "\n",
    "            # Add newlines after <li> tags\n",
    "            for li in soup.find_all(\"li\"):\n",
    "                li.insert_after(soup.new_string(\"\\n\"))\n",
    "\n",
    "            # Add newlines before and after <p> tags\n",
    "            for p in soup.find_all(\"p\"):\n",
    "                p.insert_before(soup.new_string(\"\\n\"))\n",
    "                p.insert_after(soup.new_string(\"\\n\"))\n",
    "\n",
    "            # Extract text\n",
    "            message = soup.get_text()\n",
    "            rubric.append({'instruction': message.strip()})\n",
    "        else:\n",
    "            rubric.append({'instruction': \"No instruction data found\"})\n",
    "\n",
    "        # Handling the 'docs' folder\n",
    "        if not os.path.exists('docs'):\n",
    "            os.makedirs('docs')\n",
    "\n",
    "        # Save to JSON file\n",
    "        with open(rubric_file, 'w') as f:\n",
    "            json.dump(rubric, f)\n",
    "\n",
    "        print(\"Extracted instructions and rubric\")\n",
    "    else:\n",
    "        print(f'Error: {instruction_response.text}')\n",
    "\n",
    "extract_and_save_instruction_message(base_url, course_id, discussion_topic_id, headers, rubric_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted instructions and rubric\n"
     ]
    }
   ],
   "source": [
    "# Final function to extract instructions and rubric from the Canvas LMS API.\n",
    "def extract_and_save_instruction(base_url, course_id, discussion_topic_id, headers, rubric_file):\n",
    "    instruction_url = f'{base_url}/api/v1/courses/{course_id}/discussion_topics/{discussion_topic_id}'\n",
    "    instruction_response = requests.get(instruction_url, headers=headers)\n",
    "\n",
    "    if instruction_response.ok:\n",
    "        instruction_data = instruction_response.json()\n",
    "        rubric = []\n",
    "\n",
    "        # Extract title\n",
    "        title = instruction_data.get('title')\n",
    "        if title:\n",
    "            rubric.append({'title': title})\n",
    "\n",
    "        # Try extracting from 'assignment' description first\n",
    "        description_html = instruction_data.get('assignment', {}).get('description')\n",
    "        if description_html:\n",
    "            soup = BeautifulSoup(description_html, 'html.parser')\n",
    "            description = soup.get_text()\n",
    "            rubric.append({'instruction': description})\n",
    "        else:\n",
    "            # If no description, try extracting from 'message'\n",
    "            message_html = instruction_data.get('message')\n",
    "            if message_html:\n",
    "                soup = BeautifulSoup(message_html, 'html.parser')\n",
    "\n",
    "                # Handle HTML content for message\n",
    "                for br in soup.find_all(\"br\"):\n",
    "                    br.replace_with(\"\\n\")\n",
    "                for li in soup.find_all(\"li\"):\n",
    "                    li.insert_after(soup.new_string(\"\\n\"))\n",
    "                for p in soup.find_all(\"p\"):\n",
    "                    p.insert_before(soup.new_string(\"\\n\"))\n",
    "                    p.insert_after(soup.new_string(\"\\n\"))\n",
    "\n",
    "                message = soup.get_text()\n",
    "                rubric.append({'instruction': message.strip()})\n",
    "\n",
    "        # Extract rubric and points possible, if available\n",
    "        if 'rubric' in instruction_data.get('assignment', {}):\n",
    "            rubric.extend(instruction_data['assignment']['rubric'])\n",
    "            points_possible = instruction_data['assignment'].get('points_possible')\n",
    "            if points_possible is not None:\n",
    "                rubric.append({'points_possible': points_possible})\n",
    "\n",
    "        # Handling the 'docs' folder\n",
    "        if not os.path.exists('docs'):\n",
    "            os.makedirs('docs')\n",
    "\n",
    "        # Save to JSON file\n",
    "        with open(rubric_file, 'w') as f:\n",
    "            json.dump(rubric, f)\n",
    "\n",
    "        print(\"Extracted instructions and rubric\")\n",
    "    else:\n",
    "        print(f'Error: {instruction_response.text}')\n",
    "\n",
    "extract_and_save_instruction(base_url, course_id, discussion_topic_id, headers, rubric_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
